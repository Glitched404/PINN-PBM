{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN-PBM Colab Training Notebook\n",
    "Run the cells in order to train the breakage PINN on Google Colab with GPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "1. **Runtime ▸ Change runtime type ▸ GPU** (required).\n",
    "2. Run the GPU check cell.\n",
    "3. Run the setup cell to clone the repo (or pull updates).\n",
    "4. Install dependencies.\n",
    "5. Execute the training cell (takes ~6 minutes on T4).\n",
    "6. Run the evaluation cell to visualize predictions vs. analytical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu_check"
   },
   "outputs": [],
   "source": [
    "# Check that Colab sees a GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone (or update) the PINN-PBM repository\n",
    "from pathlib import Path\n",
    "\n",
    "repo_url = \"https://github.com/Glitched404/PINN-PBM.git\"\n",
    "repo_name = \"PINN-PBM\"\n",
    "repo_path = Path(repo_name)\n",
    "\n",
    "if not repo_path.exists():\n",
    "    !git clone $repo_url\n",
    "else:\n",
    "    print(\"Repository already exists. Pulling latest changes...\")\n",
    "    %cd $repo_name\n",
    "    !git pull\n",
    "    %cd ..\n",
    "\n",
    "%cd $repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies compatible with Colab's Python 3.12 runtime\n",
    "%pip install -q -r requirements-colab.txt\n",
    "\n",
    "# Install the project package without pulling additional dependencies\n",
    "%pip install -e . --no-deps\n",
    "\n",
    "# Verify key packages after installation\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"tensorflow:\", tf.__version__)\n",
    "print(\"tensorflow_probability:\", tfp.__version__)\n",
    "\n",
    "# Ensure no dependency conflicts remain\n",
    "!pip check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_case1"
   },
   "outputs": [],
   "source": [
    "# Ensure project source is on sys.path and run full breakage experiment\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "repo_root = Path.cwd()\n",
    "source_dir = repo_root / \"src\"\n",
    "if source_dir.exists() and str(source_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(source_dir))\n",
    "\n",
    "from pinn_pbm.breakage.experiments import run_case\n",
    "\n",
    "# Configure experiment options\n",
    "CASE_TYPE = \"case1\"      # \"case1\", \"case2\", \"case3\", \"case4\"\n",
    "ADAM_EPOCHS = None        # Set to an int to override default progressive schedule\n",
    "L_BFGS_BACKEND = \"tfp\"    # \"tfp\", \"scipy\", or \"none\"\n",
    "SEED = 42\n",
    "\n",
    "result = run_case(\n",
    "    case_type=CASE_TYPE,\n",
    "    adam_epochs=ADAM_EPOCHS,\n",
    "    lbfgs=L_BFGS_BACKEND,\n",
    "    seed=SEED,\n",
    "    make_plots=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "config = result[\"config\"]\n",
    "pinn = result[\"pinn\"]\n",
    "losses = result.get(\"losses\")\n",
    "\n",
    "loss_fig = result[\"figures\"].get(\"loss\")\n",
    "pred_fig = result[\"figures\"].get(\"prediction\")\n",
    "if loss_fig is not None:\n",
    "    display(loss_fig)\n",
    "if pred_fig is not None:\n",
    "    display(pred_fig)\n",
    "\n",
    "print(\"Adam duration (s):\", result[\"adam_duration_sec\"])\n",
    "print(\"L-BFGS backend:\", result[\"lbfgs_backend\"], result[\"lbfgs\"]) \n",
    "\n",
    "if losses:\n",
    "    print(\"\\nFinal losses:\")\n",
    "    print(f\"  total: {losses['total'][-1]:.3e}\")\n",
    "    print(f\"  data:  {losses['data'][-1]:.3e}\")\n",
    "    print(f\"  phys:  {losses['physics'][-1]:.3e}\")\n",
    "\n",
    "relative_errors = result[\"relative_errors\"]\n",
    "for t_slice, rel_err in zip(config.t_slices, relative_errors):\n",
    "    print(f\"t={t_slice:.1f} → mean relative error {rel_err:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_case1"
   },
   "outputs": [],
   "source": [
    "# Evaluate and visualize predictions vs analytical solution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "v_plot = np.logspace(np.log10(v_min), np.log10(v_max), 200, dtype=np.float32)\n",
    "t_eval = np.array([0.0, 2.0, 5.0, 10.0], dtype=np.float32)\n",
    "\n",
    "f_pred = pinn.predict(v_plot, t_eval)\n",
    "f_exact = np.array([get_analytical_solution(v_plot, float(t), case_type) for t in t_eval])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(t_eval)))\n",
    "\n",
    "for i, (ax, t_val, color) in enumerate(zip(axes, t_eval, colors)):\n",
    "    ax.semilogx(v_plot, f_exact[i], color=color, lw=2.5, label=\"Analytical\")\n",
    "    ax.semilogx(v_plot, f_pred[i], 'r--', lw=2.0, label=\"PINN\")\n",
    "    ax.set_title(f\"t = {t_val:.1f}\")\n",
    "    ax.set_xlabel('Volume v')\n",
    "    ax.set_ylabel('f(v, t)')\n",
    "    ax.grid(True, which='both', ls='--', alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Case 1: PINN vs Analytical Solution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Report mean relative error for each time slice\n",
    "for i, t_val in enumerate(t_eval):\n",
    "    rel_err = np.abs((f_pred[i] - f_exact[i]) / (f_exact[i] + 1e-30))\n",
    "    print(f\"t={t_val:.1f}: mean relative error = {rel_err.mean():.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Adjust `num_epochs`, learning rates, and batch sizes for higher accuracy.\n",
    "- Swap `case_type` to `'case2'`, `'case3'`, or `'case4'` and update training data accordingly.\n",
    "- Save results to Google Drive or download with `files.download(...)` if needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
